{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2e6db8-de66-463e-8c20-672c0ebd52ff",
   "metadata": {},
   "source": [
    "# Chapter 2 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b12f725-cf27-439f-92a7-9c09234010d9",
   "metadata": {},
   "source": [
    "## 1.) - For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aac68c-2129-4773-9257-16247228e963",
   "metadata": {},
   "source": [
    "#### a.) The sample size *n* is extremely large, and the number of predictors *p* is small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e51cbb9-b75b-42c3-9269-8e1d662f579e",
   "metadata": {},
   "source": [
    "**FIRST/INCORRECT ANSWER**: An inflexible method would generally be better here. With such a large number of samples, we don't want our model reacting heavily to changes in a small amount of samples, since it is more likely to be true that a small amount of sample changes will not have a significant impact on the overall pattern of the relationship between the predictors and the outcomes.\n",
    "\n",
    "**Why was this answer incorrect?**: The statement that \"we don't want our model reacting heavily to changes in a small amount of samples\" is true, but \"small amount of samples\" is relative to the sample size. A flexible model of 10 observations may respond too much to changes in 5 samples, but a model with 1000 observations will not be affected much by 5 changes. My mistake was interpreting \"flexible\" to mean \"responding in an extreme way to a small amount of changes\", but this leaves out the context of the model. The correct version of that statment is a \"model that is **too** flexible responds in an extreme way to changes in an amount of observations that is **small with respect to the number of total samples**\". Any model can be made to be overly-flexible with respect to its observations, but the attribute of flexibility doesn't automatically imply over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95063db1-6bf0-4c51-9061-a5ddf69eb521",
   "metadata": {},
   "source": [
    "**CORRECT ANSWER**: A flexible method would be better suited to this situation than an inflexible method. Since there are lots of observations, the risk of overfitting is minimized, and we want to be able to capture the potentially complex patterns that can arise out of a large number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e363eb-1a4d-4ae6-a4f5-136ad16cb474",
   "metadata": {},
   "source": [
    "#### b.) The number of predictors *p* is extremely large, and the number of observations *n* is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e421c62-133d-4e67-94fd-6df518708252",
   "metadata": {},
   "source": [
    "An inflexible method would be better than a flexible method here. With a small number of observations, we run the risk of overfitting much earlier on the flexibility scale, and a small number of observations most likely won't produce extremely complicated patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f306f15-3f2f-45cd-bfb8-cde00caf4216",
   "metadata": {},
   "source": [
    "#### c.) The relationship between the predictors and response is highly non-linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d435c324-745d-412b-9c66-6ed5d1cda817",
   "metadata": {},
   "source": [
    "This is a situation clearly suited to a flexible method as opposed to an inflexible method. With a highly non-linear relationship, we need flexibility in order to capture that pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d188e4b8-120e-4a0e-a13c-c72dc6e82851",
   "metadata": {},
   "source": [
    "#### d.) The variance of the error terms, i.e. $σ^{2} = Var(ε)$, is extremely high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898fc949-6088-4635-be88-a585f8d6ceee",
   "metadata": {},
   "source": [
    "An inflexible model would be better here. If different training data sets have a large impact on predictions (the definition of high variance), we need to account for then noise in the dataset with a less flexible, high-bias method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b724969a-ba7e-4707-9560-7c1381d94011",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d26b591-1708-4760-9f74-9fe3b8db3993",
   "metadata": {},
   "source": [
    "## 2.) Explain whether each scenario is a classifcation or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853e47d-c5ea-4e22-a32d-13d4550fb426",
   "metadata": {},
   "source": [
    "#### a.)  We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors afect CEO salary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a8ec9-1a54-4109-b55c-2d21dc1145c1",
   "metadata": {},
   "source": [
    "This is a regression problem. We would create a model where the profit, number of employees, and industry are used to predict the CEO salary. We are interested in inference here.\n",
    "`n = 500` and `p = 3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51959b13-52ec-4fb2-8f72-1a287af40f06",
   "metadata": {},
   "source": [
    "#### b.) We are considering launching a new product and wish to know whether it will be a *success* or a *failure*. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or a failure, price charged for the product, marketing budget, competition price, and ten other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed834b1-bdf5-476b-b250-48c5fdcf6bf5",
   "metadata": {},
   "source": [
    "This is a classification problem, with *success* and *failure* buckets. Prediction is the interest. Here we have `n = 20` and `p = 13`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ead4f-a699-49ed-863f-8976790b8dbb",
   "metadata": {},
   "source": [
    "#### c.)  We are interested in predicting the % change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed6670-1702-49b1-8ee6-5ce5a7b0a646",
   "metadata": {},
   "source": [
    "This is a regression problem, with the prediction being the percent change in the USD/Euro exchange rate. Prediction is the obvious interest here, with `n = 52` (number of weeks in a year) and `p = 3`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865f696-31cd-44d7-892b-d81a566dc427",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eebecba7-c631-4d71-9a90-85bb18df9c31",
   "metadata": {},
   "source": [
    "## 3.) We now revisit the bias-variance decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182742c-c4b9-417d-bf70-d587473156d9",
   "metadata": {},
   "source": [
    "#### a.) Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddee2c6-dd7a-4f18-9cc1-49cf589fa7f1",
   "metadata": {},
   "source": [
    "Sketch in LiquidText."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49136ad-164a-4334-9bbe-e3f830783169",
   "metadata": {},
   "source": [
    "#### b.) Explain why each of the five curves has the shape displayed in part (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a3655-51c6-4323-ba5d-2d1c8cf5e459",
   "metadata": {},
   "source": [
    "- Bias - bias has an inverse relationship to flexibility, so when flexibility is low, bias will be high, and will decrease as the flexibility increases, rapidly at first and then more gradually.\n",
    "- Variance - variance has the opposite behavior from bias. It will start low, but as method flexibility increases, variance will increase along with it.\n",
    "- Training error - the training area will always decrease as flexibility increases.\n",
    "- Test error - The training area will have a U-shape, at first decreasing as flexibility increases, but then increasing again as too much flexibility starts to over-fit the data..\n",
    "- Bayes error - This is a constant (though unknown), so it is represented as a horizontal line whose value is just below the minimum value of the test error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9b132-71ef-4fe2-92f4-df1bd8eaa752",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e1a3eff-fbb0-45b2-8aee-19a6dfbca049",
   "metadata": {},
   "source": [
    "## 4.) You will now think of some real-life applications for statistical learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb66ab-82e9-4d39-a6b7-a300919de0dd",
   "metadata": {},
   "source": [
    "#### a.) Describe three real-life applications in which *classification* might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c29ba-58b6-41d2-9f68-c68958acdd3d",
   "metadata": {},
   "source": [
    "- Classifying email into \"spam\", \"promotions\", and \"social\" categories, like Gmail does. The response is an integer that represents one of the three (or more) categories, and the predictors could be things like word choice, frequency of exclamation marks, length of email, amount of attachments, etc. The goal here is prediction. We wouldn't be super concerned with what constituted a spam or social email, just that it was filtered into the correct inbox.\n",
    "- Classifying a current market as a \"bull\" or \"bear\" market. The response would be one of those two categories, and the predictors would be things like recent trade volume, market cap, performance over different time periods, options distributions, and any number of global economic factors. Here inference would be the goal, as we would be interested in how different factors affect the market.\n",
    "- Classifying a song into any genres. The response would be something like \"rock\", \"pop\", or \"rap\", and the predictors could be song length, frequency of selected words, topic (love story, breakup, partying, reflection, etc.), or even instrumnents used. This application would most likely only be concerned with prediction, to help sort songs into their respective genre buckets, like Spotify or similar apps do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e264a20-d54c-41b6-9793-46cce952b28f",
   "metadata": {},
   "source": [
    "#### b.) Describe three real-life applications in which *regression* might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f7893-88c7-40cb-b5b3-72f396451596",
   "metadata": {},
   "source": [
    "- Predicting rainfall amount on a farm. Response would be some number representing amount of rainfall, and predictors could be previous day's or week's rainfall amount, geographic location, temperature, and cloud cover. Prediction would be the goal here, as that would be the information that would potentially drive a farmer's decision regarding some things.\n",
    "- Predicting average house prices for a given month/year. Response would be a numerical value representing the average (or maybe median) price of a house in a certain area. Predictors could be current listing count, average/median price of houses in the previous month, average time on the market for recent listings, and population/population growth of the area. The application would probably be more focused on inference, as the interest is in what it is that has an impact on the price of houses.\n",
    "- Predicting future salary of an individual. The response would be a yearly salary that a person would be expected to make at a given age, and the predictors would be things like educatio completed, zip code, family economic status, race, and field of study (if college was completed). This model would most likely be focused on inference, to learn about what can be done to mitigate negative impacts on future salary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d880532-44fe-4074-a11b-2df32ae6e9fe",
   "metadata": {},
   "source": [
    "#### c.) Describe three real-life applications in which *cluster analysis* might be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4834b75-882e-4112-86e2-f919bb1c434d",
   "metadata": {},
   "source": [
    "- Finding the types of users of a particular product or service.\n",
    "- Finding restaurant types and frequencies in a given city.\n",
    "- Finding patterns in grade distributions for a highschool or university."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e36703b-f3cf-482d-8378-bf8d59e487c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7773b4a7-526f-46ad-b64e-e261837fe1fe",
   "metadata": {},
   "source": [
    "## 5.) What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach)? When might a less flexible approach be preferred?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666108ab-e1ac-4a55-b690-1c052d2a7d9c",
   "metadata": {},
   "source": [
    "A flexible approach to a problem can allow your model to find complicated patters tha appear in the data. If there is a dataset that contains very non-linear underlying relationships, a flexible approach will be allow you to capture those relationships. The disadvantage comes when the relationships in a dataset are actually relatively simple, maybe linear, because you're then prone to overfitting the data. In these instances, you would prefer a less flexible approach to avoid the problem of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802b701-265d-47e9-ba3b-7a364e226817",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a270cfba-f112-42a6-b144-e94b0333a246",
   "metadata": {},
   "source": [
    "## 6.) Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a non-parametric approach)? What are its disadvantages?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f5bae-c438-4a14-8702-191c2482158d",
   "metadata": {},
   "source": [
    "A parametric approach assumes that we know the general shape of `f`, and can just focus on finding the parameters/weights of the function. Computationaly, this is much easier than trying to figure out what `f` is from scratch; but it also means that a certain amount of your final result's accuracy is going to be entirely dependant on how close you were in estimating the initial shape of the function.\n",
    "\n",
    "A non-parametric approach could potentially lead to a more accurate final model, but it is much more computationally difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a35e1f-1aca-4f14-a511-5b5548f08583",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efa10b15-cb92-4e0f-8d1d-3cb686802fdc",
   "metadata": {},
   "source": [
    "## 7.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
